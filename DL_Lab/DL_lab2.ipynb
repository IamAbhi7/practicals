{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0eaf790",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "782/782 - 3s - loss: 0.5288 - accuracy: 0.7447 - val_loss: 0.3370 - val_accuracy: 0.8692 - 3s/epoch - 4ms/step\n",
      "Epoch 2/20\n",
      "782/782 - 3s - loss: 0.2704 - accuracy: 0.8954 - val_loss: 0.2875 - val_accuracy: 0.8833 - 3s/epoch - 3ms/step\n",
      "Epoch 3/20\n",
      "782/782 - 3s - loss: 0.2135 - accuracy: 0.9195 - val_loss: 0.2798 - val_accuracy: 0.8850 - 3s/epoch - 4ms/step\n",
      "Epoch 4/20\n",
      "782/782 - 3s - loss: 0.1791 - accuracy: 0.9345 - val_loss: 0.2888 - val_accuracy: 0.8824 - 3s/epoch - 4ms/step\n",
      "Epoch 5/20\n",
      "782/782 - 4s - loss: 0.1544 - accuracy: 0.9458 - val_loss: 0.3064 - val_accuracy: 0.8782 - 4s/epoch - 6ms/step\n",
      "Epoch 6/20\n",
      "782/782 - 3s - loss: 0.1351 - accuracy: 0.9543 - val_loss: 0.3336 - val_accuracy: 0.8720 - 3s/epoch - 4ms/step\n",
      "Epoch 7/20\n",
      "782/782 - 3s - loss: 0.1191 - accuracy: 0.9592 - val_loss: 0.3552 - val_accuracy: 0.8716 - 3s/epoch - 4ms/step\n",
      "Epoch 8/20\n",
      "782/782 - 3s - loss: 0.1058 - accuracy: 0.9656 - val_loss: 0.3866 - val_accuracy: 0.8636 - 3s/epoch - 4ms/step\n",
      "Epoch 9/20\n",
      "782/782 - 3s - loss: 0.0931 - accuracy: 0.9709 - val_loss: 0.4070 - val_accuracy: 0.8652 - 3s/epoch - 4ms/step\n",
      "Epoch 10/20\n",
      "782/782 - 3s - loss: 0.0827 - accuracy: 0.9767 - val_loss: 0.4397 - val_accuracy: 0.8612 - 3s/epoch - 4ms/step\n",
      "Epoch 11/20\n",
      "782/782 - 3s - loss: 0.0738 - accuracy: 0.9801 - val_loss: 0.4795 - val_accuracy: 0.8554 - 3s/epoch - 4ms/step\n",
      "Epoch 12/20\n",
      "782/782 - 3s - loss: 0.0663 - accuracy: 0.9820 - val_loss: 0.5126 - val_accuracy: 0.8510 - 3s/epoch - 4ms/step\n",
      "Epoch 13/20\n",
      "782/782 - 3s - loss: 0.0589 - accuracy: 0.9844 - val_loss: 0.5619 - val_accuracy: 0.8464 - 3s/epoch - 4ms/step\n",
      "Epoch 14/20\n",
      "782/782 - 3s - loss: 0.0513 - accuracy: 0.9873 - val_loss: 0.5911 - val_accuracy: 0.8506 - 3s/epoch - 4ms/step\n",
      "Epoch 15/20\n",
      "782/782 - 3s - loss: 0.0450 - accuracy: 0.9890 - val_loss: 0.6249 - val_accuracy: 0.8456 - 3s/epoch - 4ms/step\n",
      "Epoch 16/20\n",
      "782/782 - 3s - loss: 0.0391 - accuracy: 0.9910 - val_loss: 0.6753 - val_accuracy: 0.8443 - 3s/epoch - 4ms/step\n",
      "Epoch 17/20\n",
      "782/782 - 3s - loss: 0.0344 - accuracy: 0.9919 - val_loss: 0.7228 - val_accuracy: 0.8438 - 3s/epoch - 4ms/step\n",
      "Epoch 18/20\n",
      "782/782 - 3s - loss: 0.0304 - accuracy: 0.9934 - val_loss: 0.7680 - val_accuracy: 0.8395 - 3s/epoch - 4ms/step\n",
      "Epoch 19/20\n",
      "782/782 - 3s - loss: 0.0258 - accuracy: 0.9946 - val_loss: 0.8228 - val_accuracy: 0.8384 - 3s/epoch - 4ms/step\n",
      "Epoch 20/20\n",
      "782/782 - 3s - loss: 0.0224 - accuracy: 0.9950 - val_loss: 0.8792 - val_accuracy: 0.8380 - 3s/epoch - 4ms/step\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 0.8792 - accuracy: 0.8380\n",
      "Test Loss: 0.8792011141777039\n",
      "Test Accuracy: 0.8380399942398071\n",
      "782/782 [==============================] - 1s 1ms/step\n",
      "Number of positive reviews: 12589\n",
      "Number of negative reviews: 12411\n"
     ]
    }
   ],
   "source": [
    "#Import the necessary libraries:\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences     #imp remember pad_sequences\n",
    "import numpy as np\n",
    "                \n",
    "# Set the maximum number of words to consider in the vocabulary\n",
    "max_words = 10000\n",
    "\n",
    "# Load the IMDB dataset\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_words)   #imp remember imdb.load_data(num_words=max_words)\n",
    "\n",
    "# Pad sequences to a fixed length\n",
    "max_sequence_length = 250\n",
    "X_train = pad_sequences(X_train, maxlen=max_sequence_length)\n",
    "X_test = pad_sequences(X_test, maxlen=max_sequence_length)   #remember both are X\n",
    "\n",
    "# Build the deep neural network model using sequential API\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(max_words,16,input_length=max_sequence_length))\n",
    "model.add(tf.keras.Flatten())\n",
    "model.add(tf.keras.Dense(16,activation='relu'))\n",
    "model.add(tf.keras.Dense(1,activation='sigmoid'))\n",
    "\n",
    "# Compile the model by specifying the optimizer, loss function, and metrics:\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), verbose=2)\n",
    "\n",
    "#Evaluate the model on the test set and print the test loss and accuracy:\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Count the number of positive and negative reviews\n",
    "positive_count = np.count_nonzero(y_pred == 1)\n",
    "negative_count = np.count_nonzero(y_pred == 0)\n",
    "\n",
    "print(f\"Number of positive reviews: {positive_count}\")\n",
    "print(f\"Number of negative reviews: {negative_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0201e998",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary libraries:\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb                                #imp remember tensorflow.\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ab70075a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the maximum number of words to consider in the vocabulary\n",
    "max_words = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "30dc166c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the IMDB dataset\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f7d04a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences to a fixed length\n",
    "max_sequence_length = 200\n",
    "X_train = pad_sequences(X_train, maxlen=max_sequence_length)\n",
    "X_test = pad_sequences(X_test, maxlen=max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "19538182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the deep neural network model using sequential API\n",
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Embedding(max_words, 16, input_length=max_sequence_length),\n",
    "#     tf.keras.layers.Flatten(),\n",
    "#     tf.keras.layers.Dense(16, activation='relu'),\n",
    "#     tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(max_words,16,input_length=max_sequence_length))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(16,activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "05fcc8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model by specifying the optimizer, loss function, and metrics:\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "df3aa055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 - 4s - loss: 0.4248 - accuracy: 0.7801 - val_loss: 0.2931 - val_accuracy: 0.8738 - 4s/epoch - 5ms/step\n",
      "Epoch 2/5\n",
      "782/782 - 4s - loss: 0.1636 - accuracy: 0.9412 - val_loss: 0.3252 - val_accuracy: 0.8674 - 4s/epoch - 5ms/step\n",
      "Epoch 3/5\n",
      "782/782 - 4s - loss: 0.0464 - accuracy: 0.9878 - val_loss: 0.4307 - val_accuracy: 0.8560 - 4s/epoch - 5ms/step\n",
      "Epoch 4/5\n",
      "782/782 - 4s - loss: 0.0095 - accuracy: 0.9988 - val_loss: 0.5043 - val_accuracy: 0.8561 - 4s/epoch - 6ms/step\n",
      "Epoch 5/5\n",
      "782/782 - 3s - loss: 0.0024 - accuracy: 0.9998 - val_loss: 0.5512 - val_accuracy: 0.8572 - 3s/epoch - 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28392f0e220>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "de556a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 1.1044 - accuracy: 0.8605\n",
      "Test Loss: 1.1043684482574463\n",
      "Test Accuracy: 0.860480010509491\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model on the test set and print the test loss and accuracy:\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "730ce0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)   #imp remember astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9a131a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of positive and negative reviews\n",
    "positive_count = np.count_nonzero(y_pred == 1)   #imp remember \n",
    "negative_count = np.count_nonzero(y_pred == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "42512011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive reviews: 12470\n",
      "Number of negative reviews: 12530\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of positive reviews: {positive_count}\")\n",
    "print(f\"Number of negative reviews: {negative_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5336c942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc24384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94e62885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 - 10s - loss: 0.4172 - accuracy: 0.7805 - val_loss: 0.2922 - val_accuracy: 0.8757 - 10s/epoch - 13ms/step\n",
      "Epoch 2/10\n",
      "782/782 - 9s - loss: 0.1987 - accuracy: 0.9244 - val_loss: 0.2990 - val_accuracy: 0.8748 - 9s/epoch - 12ms/step\n",
      "Epoch 3/10\n",
      "782/782 - 9s - loss: 0.1175 - accuracy: 0.9589 - val_loss: 0.3714 - val_accuracy: 0.8606 - 9s/epoch - 12ms/step\n",
      "Epoch 4/10\n",
      "782/782 - 9s - loss: 0.0565 - accuracy: 0.9825 - val_loss: 0.4908 - val_accuracy: 0.8609 - 9s/epoch - 11ms/step\n",
      "Epoch 5/10\n",
      "782/782 - 9s - loss: 0.0247 - accuracy: 0.9926 - val_loss: 0.6838 - val_accuracy: 0.8480 - 9s/epoch - 12ms/step\n",
      "Epoch 6/10\n",
      "782/782 - 10s - loss: 0.0165 - accuracy: 0.9948 - val_loss: 0.7820 - val_accuracy: 0.8481 - 10s/epoch - 12ms/step\n",
      "Epoch 7/10\n",
      "782/782 - 9s - loss: 0.0205 - accuracy: 0.9931 - val_loss: 1.1320 - val_accuracy: 0.8181 - 9s/epoch - 11ms/step\n",
      "Epoch 8/10\n",
      "782/782 - 9s - loss: 0.0157 - accuracy: 0.9946 - val_loss: 0.8028 - val_accuracy: 0.8553 - 9s/epoch - 11ms/step\n",
      "Epoch 9/10\n",
      "782/782 - 9s - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.9576 - val_accuracy: 0.8596 - 9s/epoch - 12ms/step\n",
      "Epoch 10/10\n",
      "782/782 - 10s - loss: 0.0147 - accuracy: 0.9953 - val_loss: 1.0126 - val_accuracy: 0.8416 - 10s/epoch - 13ms/step\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 1.0126 - accuracy: 0.8416\n",
      "Test Loss: 1.0125852823257446\n",
      "Test Accuracy: 0.8415600061416626\n",
      "782/782 [==============================] - 2s 3ms/step\n",
      "Number of positive reviews: 10761\n",
      "Number of negative reviews: 14239\n"
     ]
    }
   ],
   "source": [
    "# Compile the model by specifying the optimizer, loss function, and metrics\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), verbose=2)\n",
    "\n",
    "# Evaluate the model on the test set and print the test loss and accuracy\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Count the number of positive and negative reviews\n",
    "positive_count = np.count_nonzero(y_pred == 1)\n",
    "negative_count = np.count_nonzero(y_pred == 0)\n",
    "\n",
    "print(f\"Number of positive reviews: {positive_count}\")\n",
    "print(f\"Number of negative reviews: {negative_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d85dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0be58ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
